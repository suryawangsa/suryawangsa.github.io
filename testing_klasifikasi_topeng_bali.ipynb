{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNU7WunlkTQQk7GAwP6Gmn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suryawangsa/suryawangsa.github.io/blob/main/testing_klasifikasi_topeng_bali.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePHy0cnlmV38",
        "outputId": "e5c8a5a2-a717-447a-8fa8-6240e21fbf01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/suryapradana/balinese-mask?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 0.99G/0.99G [00:14<00:00, 71.6MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset path: /root/.cache/kagglehub/datasets/suryapradana/balinese-mask/versions/1\n",
            "Isi folder: ['balinese mask']\n"
          ]
        }
      ],
      "source": [
        "!pip install -q kagglehub\n",
        "import kagglehub\n",
        "import os\n",
        "\n",
        "\n",
        "path = kagglehub.dataset_download(\"suryapradana/balinese-mask\")\n",
        "print(\"Dataset path:\", path)\n",
        "print(\"Isi folder:\", os.listdir(path))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import os\n",
        "\n",
        "# Download dataset\n",
        "path = kagglehub.dataset_download(\"suryapradana/balinese-mask\")\n",
        "print(\"Path ke dataset:\", path)\n",
        "\n",
        "# Lihat isi folder utama\n",
        "print(\"Isi folder utama:\")\n",
        "print(os.listdir(path))\n",
        "\n",
        "# Jika perlu, lihat isi dalam subfolder\n",
        "for item in os.listdir(path):\n",
        "    item_path = os.path.join(path, item)\n",
        "    if os.path.isdir(item_path):\n",
        "        print(f\"Isi folder '{item}':\", os.listdir(item_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-3-a6CYmjdi",
        "outputId": "01065868-b19c-4574-aeae-07dfd8985480"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path ke dataset: /kaggle/input/balinese-mask\n",
            "Isi folder utama:\n",
            "['balinese mask']\n",
            "Isi folder 'balinese mask': ['bujuh', 'penasar', 'tua', 'wijil', 'dalem', 'sidakarya', 'keras']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dir = os.path.join(path, \"balinese mask\")\n",
        "# Cek ulang\n",
        "print(\"Folder dataset_dir:\", dataset_dir)\n",
        "print(\"Isi:\", os.listdir(dataset_dir))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZfXPZFmn7mT",
        "outputId": "7e75bd2e-67f4-4a6e-ef06-5cc988298a59"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder dataset_dir: /kaggle/input/balinese-mask/balinese mask\n",
            "Isi: ['bujuh', 'penasar', 'tua', 'wijil', 'dalem', 'sidakarya', 'keras']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Path sudah benar\n",
        "dataset_dir = os.path.join(path, \"balinese mask\")\n",
        "\n",
        "# Output folder\n",
        "base_output = \"/content/dataset_split\"\n",
        "train_dir = os.path.join(base_output, \"train\")\n",
        "val_dir = os.path.join(base_output, \"val\")\n",
        "\n",
        "# Buat folder train dan val serta subfolder per kelas\n",
        "for split_dir in [train_dir, val_dir]:\n",
        "    os.makedirs(split_dir, exist_ok=True)\n",
        "    for class_name in os.listdir(dataset_dir):\n",
        "        os.makedirs(os.path.join(split_dir, class_name), exist_ok=True)\n",
        "\n",
        "# Bagi data\n",
        "for class_name in os.listdir(dataset_dir):\n",
        "    class_path = os.path.join(dataset_dir, class_name)\n",
        "\n",
        "    # Ambil hanya file (hindari folder seperti 'bak')\n",
        "    images = [f for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))]\n",
        "\n",
        "    train_imgs, val_imgs = train_test_split(images, test_size=0.2, random_state=42)\n",
        "\n",
        "    for img in train_imgs:\n",
        "        shutil.copy2(os.path.join(class_path, img), os.path.join(train_dir, class_name, img))\n",
        "\n",
        "    for img in val_imgs:\n",
        "        shutil.copy2(os.path.join(class_path, img), os.path.join(val_dir, class_name, img))\n",
        "\n",
        "print(\"✅ Dataset berhasil dibagi menjadi train dan val.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2uVumxjoNUa",
        "outputId": "b5131d1b-12a9-46b1-97f6-cf8d3166dfef"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset berhasil dibagi menjadi train dan val.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"/content/dataset_split/train\",\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"/content/dataset_split/val\",\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "# Percepat loading\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36Lg5bCBozay",
        "outputId": "09dc9706-36f0-4508-e41e-f242cf3918a7"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 318 files belonging to 8 classes.\n",
            "Found 104 files belonging to 8 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Load base MobileNetV2 tanpa output layer\n",
        "base_model = MobileNetV2(input_shape=(224, 224, 3),\n",
        "                         include_top=False,\n",
        "                         weights='imagenet')\n",
        "base_model.trainable = False  # freeze dulu\n",
        "raw_train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"/content/dataset_split/train\",\n",
        "    image_size=(224, 224),\n",
        "    batch_size=32\n",
        ")\n",
        "class_names = raw_train_ds.class_names\n",
        "\n",
        "train_ds = raw_train_ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "# Build model klasifikasi\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(len(class_names), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "l2L1vjENo3KJ",
        "outputId": "8ad0cb16-d3c7-4b6d-ef68-d0e9827abb0e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 318 files belonging to 8 classes.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ mobilenetv2_1.00_224            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m2,257,984\u001b[0m │\n",
              "│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m163,968\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m1,032\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ mobilenetv2_1.00_224            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">163,968</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,032</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,422,984\u001b[0m (9.24 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,422,984</span> (9.24 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m165,000\u001b[0m (644.53 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">165,000</span> (644.53 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=10  # bisa kamu sesuaikan\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3t2tByo5ps4L",
        "outputId": "f4007efa-0252-431c-ea1a-edb3fb44448d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 5s/step - accuracy: 0.2171 - loss: 2.2577 - val_accuracy: 0.5673 - val_loss: 1.2942\n",
            "Epoch 2/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 4s/step - accuracy: 0.5536 - loss: 1.3072 - val_accuracy: 0.7308 - val_loss: 0.9078\n",
            "Epoch 3/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 6s/step - accuracy: 0.6960 - loss: 0.8841 - val_accuracy: 0.9231 - val_loss: 0.5097\n",
            "Epoch 4/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 6s/step - accuracy: 0.8734 - loss: 0.5677 - val_accuracy: 0.8942 - val_loss: 0.4006\n",
            "Epoch 5/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 5s/step - accuracy: 0.8808 - loss: 0.4495 - val_accuracy: 0.9231 - val_loss: 0.3824\n",
            "Epoch 6/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6s/step - accuracy: 0.9109 - loss: 0.3547 - val_accuracy: 0.9327 - val_loss: 0.2772\n",
            "Epoch 7/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 5s/step - accuracy: 0.9039 - loss: 0.3041 - val_accuracy: 0.9615 - val_loss: 0.1848\n",
            "Epoch 8/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6s/step - accuracy: 0.9665 - loss: 0.2172 - val_accuracy: 0.9423 - val_loss: 0.1959\n",
            "Epoch 9/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 6s/step - accuracy: 0.9588 - loss: 0.2212 - val_accuracy: 0.9615 - val_loss: 0.1546\n",
            "Epoch 10/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 5s/step - accuracy: 0.9805 - loss: 0.1375 - val_accuracy: 0.9808 - val_loss: 0.1144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "val_tua_path = \"/content/dataset_split/val/tua\"\n",
        "print(\"Isi folder val/tua:\")\n",
        "print(os.listdir(val_tua_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXl7qY41tQrT",
        "outputId": "2091afca-3099-41c0-9805-c33002e1bbfa"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Isi folder val/tua:\n",
            "['173.jpg', '170.JPG', '161.jpg', '159.jpg', '168.JPG', '171.jpg', '177.JPG', '191.jpg', '162.jpg', '180.JPG', '160.jpg', '172.jpg', '192.JPG', '197.jpg', '184.jpg', '193.JPG', '185.jpg', '190.jpg', '169.JPG', '187.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Contoh prediksi 1 gambar\n",
        "img_path = \"/content/dataset_split/val/tua/173.jpg\"\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "predicted_class = class_names[np.argmax(predictions)]\n",
        "\n",
        "print(\"Prediksi:\", predicted_class)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzuhOK1Ct3n5",
        "outputId": "632b86f6-47f5-4a96-c580-2ca4b0acaebf"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "Prediksi: tua\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"mobilenetv2_topeng_bali.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00XeRO5FuJF7",
        "outputId": "81543677-0974-4d10-b9b9-7066926c5d7c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "val_keras_path = \"/content/dataset_split/val/keras\"\n",
        "print(\"Isi folder val/keras:\")\n",
        "print(os.listdir(val_keras_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "te_spXgyujZJ",
        "outputId": "00f14fd8-eb1e-41e6-966a-3b532843f2a4"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Isi folder val/keras:\n",
            "['101.jpg', '104.jpg', '140.JPG', '129.JPG', '142.jpg', '146.JPG', '100.JPG', '136.jpg', '111.jpg', '125.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Contoh prediksi 1 gambar\n",
        "img_path = \"/content/dataset_split/val/keras/101.jpg\"\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "predicted_class = class_names[np.argmax(predictions)]\n",
        "\n",
        "print(\"Prediksi:\", predicted_class)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUJIcyR8uzla",
        "outputId": "9db1d146-1c7e-43e8-a80e-49a583eba7b8"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
            "Prediksi: keras\n"
          ]
        }
      ]
    }
  ]
}